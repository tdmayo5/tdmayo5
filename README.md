# tdmayo5-README.md

# Trevor Mayo | Data Engineer

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=flat&logo=linkedin&logoColor=white)](your-linkedin-url) [![Email](https://img.shields.io/badge/Email-tdmayo5@gmail.com-D14836?style=flat&logo=gmail&logoColor=white)](mailto:tdmayo5@gmail.com) [![Phone](https://img.shields.io/badge/Phone-(336)%20383--6258-25D366?style=flat&logo=whatsapp&logoColor=white)](tel:3363836258)

## üëã Hey there!

I'm Trevor, a **Data Engineer** with over 3 years of hands-on experience building data pipelines and solving complex problems at **Huntington National Bank**. I love turning messy data into clean, actionable insights that actually help businesses make better decisions.

What gets me excited? Taking a tangled mess of data sources and transforming them into smooth, automated pipelines that just work. I've had the chance to work on everything from fraud detection systems to executive dashboards, and honestly, there's nothing quite like seeing a pipeline you built running smoothly in production.

---

## üíº My Journey So Far

### üè¶ **Data Engineer** | Huntington National Bank | *Dec 2023 ‚Äì Present*

Right now, I'm focused on building robust data solutions that our fraud detection and analytics teams rely on daily. Some of the cool stuff I've been working on:

- Built geo-spatial data pipelines using AWS Glue and Athena - turns out processing location data at scale is pretty fascinating  
- Automated our fraud detection data ingestion, which means less manual work and more accurate results  
- Spent time optimizing existing workflows to play nice with our reporting systems  
- Really enjoy the collaborative aspect - working with business stakeholders to understand what they actually need (not just what they think they need!)

### üìä **Operational Analytics Data Scientist** | Huntington National Bank | *Jun 2022 ‚Äì Dec 2023*

This role was where I really fell in love with data engineering. I got to build automated pipelines that made everyone's life easier:

- Created BI pipelines that cut manual work by 30% - seeing that kind of impact never gets old  
- Dove deep into AWS optimization, particularly with Athena and S3 for handling large datasets  
- Built data models that executives actually use for decision-making (integrated with Tableau)  
- Established some ETL frameworks that other teams still use today

### üîç **Fraud Data Scientist** | Huntington National Bank | *Jan 2022 ‚Äì Jun 2022*

My first real taste of production data work. Learned a ton about the importance of data quality and compliance:

- Developed predictive models for fraud detection using Python and historical transaction data  
- Built solutions for regulatory reporting (learned that compliance is no joke in banking!)  
- Worked closely with compliance teams to make sure everything met audit standards

---

## üõ†Ô∏è What I Work With

### **Cloud Platforms**
I'm comfortable with both **Google Cloud** and **AWS**. On the Google side, I work with BigQuery, Cloud Storage, Composer, and VertexAI. For AWS, it's mainly Glue, Athena, S3, and Redshift.

### **Languages & Tools**
**Python** is my go-to for most data work, along with **SQL** (including PL/pgSQL). I also know some **R** from my earlier analytics days. For orchestration, I've been using **Prefect** and am currently diving deeper into **Airflow**.

### **Data Engineering Stuff**
I've gotten pretty good at ETL/ELT development, data modeling, and working with data warehouses. Lately, I've been exploring **Medallion Architecture** patterns and getting more into **dbt** for transformations.

### **The People Side**
One thing I've learned is that technical skills only get you so far. I really value working with cross-functional teams, translating business needs into technical solutions, and making sure stakeholders understand what we're building and why.

---

## üèóÔ∏è Projects I'm Proud Of

### üèÄ **NBA Analytics Data Pipeline** | *2025*
*Personal project that scratches my basketball itch*

I built this end-to-end pipeline to analyze NBA content performance data, mainly because I wanted to learn more about modern data architecture patterns. It follows the Medallion Architecture approach (Bronze ‚Üí Silver ‚Üí Gold layers) and uses GCP services like BigQuery and Cloud Storage.

The fun part was setting up the entire workflow - from ingesting raw JSON data to creating analytics-ready datasets using dbt. I'm using Prefect for orchestration and planning to add GitHub Actions for CI/CD. It's been a great way to experiment with tools I don't get to use at work.

### ‚ö° **ETL Performance Optimization** | *Huntington National Bank, 2022*
*The project that taught me optimization matters*

This was one of those projects where I got to roll up my sleeves and really dig into performance issues. We had some fraud detection pipelines that were getting sluggish, so I worked with stakeholders to identify bottlenecks and redesign the infrastructure.

The end result? We reduced workload by 30% and saved about $6.5K annually. More importantly, I learned that sometimes the best technical solution is the one that involves talking to people to understand the real problem.

---

## üéì Background

**Bachelor of Science, Computer Science**  
North Carolina A&T State University | *Class of 2021*

I'm someone who believes in continuous learning. Right now I'm diving deeper into Airflow orchestration, advanced dbt patterns, and modern data architecture approaches. The field moves fast, and I love keeping up with new tools and techniques.

---

## üìà How I Got Here

**2025**: Continuing to grow as a data engineer and exploring leadership opportunities  
**2023-Present**: Stepped into a more senior data engineering role with greater architectural responsibilities  
**2022-2023**: Transitioned from analytics to engineering, discovered my passion for building data systems  
**2022**: Started as a data scientist focused on fraud detection  
**2021**: Fresh CS graduate, ready to dive into the data world

---

## üìû Let's Chat

I love talking about data engineering challenges, new tools, and interesting problems. Whether you're dealing with a tricky pipeline issue or just want to geek out about data architecture, I'm always up for a good conversation.

**What I'm Into**: Modern data stack ‚Ä¢ Cloud architecture ‚Ä¢ Making data accessible ‚Ä¢ Solving complex business problems with simple solutions

**How I Work**: Collaborative ‚Ä¢ Always learning ‚Ä¢ Results-focused

---

‚≠ê **Feel free to reach out if you want to discuss data engineering, share war stories, or just connect!**
